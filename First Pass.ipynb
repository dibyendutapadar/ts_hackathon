{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error,mean_absolute_percentage_error, r2_score\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.statespace.dynamic_factor import DynamicFactor\n",
    "from prophet import Prophet\n",
    "from statsmodels.tsa.forecasting.theta import ThetaModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import openai\n",
    "from pydantic import BaseModel, Field\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI API Key (Replace with your own key)\n",
    "OPENAI_API_KEY = \"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\"\n",
    "client = openai.OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load & Transform Data\n",
    "def load_and_transform(file_path, sheet_name=0):\n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "    df = df.melt(id_vars=[df.columns[0]], var_name=\"Month\", value_name=\"Value\")\n",
    "    df.columns = [\"Item\", \"Month\", \"Value\"]\n",
    "    df[\"Month\"] = pd.to_datetime(df[\"Month\"], format=\"%b-%y\")  # Adjust format as needed\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ForecastEntry(BaseModel):\n",
    "    month: str\n",
    "    value: float\n",
    "\n",
    "class ForecastResponse(BaseModel):\n",
    "    forecast: list[ForecastEntry]\n",
    "    summary: str\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def forecast_with_openai(train, forecast_periods):\n",
    "    history_text = \"\\n\".join(\n",
    "        f\"In {row.Month.strftime('%b-%y')}, the value was {row.Value}.\" for _, row in train.iterrows()\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Here is a time-series of financial data:\n",
    "    {history_text}\n",
    "    Based on the above pattern, predict the next {forecast_periods} months and provide a summary explanation of the forecast.\n",
    "    The summary should be a little detailed. How is the trend and seasonality, how they are affecting the months, etc.\n",
    "    Don't use any model or code, use natural reasoning ability for forecasting.\n",
    "    Return the response as a JSON object with keys 'forecast' and 'summary'.\n",
    "    \"\"\"\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        response_format={\n",
    "            \"type\": \"json_schema\",\n",
    "            \"json_schema\": {\n",
    "                \"name\": \"forecast_schema\",  # Add a descriptive name for your schema\n",
    "                \"schema\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"forecast\": {\n",
    "                            \"type\": \"array\",\n",
    "                            \"items\": {\n",
    "                                \"type\": \"object\",\n",
    "                                \"properties\": {\n",
    "                                    \"month\": {\"type\": \"string\"},\n",
    "                                    \"value\": {\"type\": \"number\"}\n",
    "                                },\n",
    "                                \"required\": [\"month\", \"value\"]\n",
    "                            }\n",
    "                        },\n",
    "                        \"summary\": {\"type\": \"string\"}\n",
    "                    },\n",
    "                    \"required\": [\"forecast\", \"summary\"],\n",
    "                    \"additionalProperties\": False\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        store=True\n",
    "    )\n",
    "\n",
    "    response_data = json.loads(response.choices[0].message.content)\n",
    "    print(\"==== response ====\")\n",
    "    print(response_data)\n",
    "    parsed_forecast = ForecastResponse(**response_data)\n",
    "    return parsed_forecast.forecast, parsed_forecast.summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecasting Function\n",
    "def forecast_time_series(df, target_item, forecast_periods=12):\n",
    "    data = df[df[\"Item\"] == target_item][[\"Month\", \"Value\"]].sort_values(\"Month\")\n",
    "    train, test = train_test_split(data, test_size=forecast_periods, shuffle=False)\n",
    "\n",
    "    models = {\n",
    "        \"ARIMA\": ARIMA(train[\"Value\"], order=(1, 1, 1)).fit(),\n",
    "        \"Holt-Winters\": ExponentialSmoothing(train[\"Value\"], trend=\"add\", seasonal=\"add\", seasonal_periods=12).fit(),\n",
    "        \"SARIMA\": SARIMAX(train[\"Value\"], order=(1, 1, 1), seasonal_order=(1, 1, 1, 12)).fit(),\n",
    "        \"Prophet\": Prophet().fit(train.rename(columns={\"Month\": \"ds\", \"Value\": \"y\"})),\n",
    "        # \"Theta\": ThetaModel(train[\"Value\"]).fit(),\n",
    "        # \"Dynamic Factor\": DynamicFactor(train[\"Value\"], k_factors=1).fit()\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "    test_df = pd.DataFrame({\"ds\": test[\"Month\"]})\n",
    "\n",
    "    for name, model in models.items():\n",
    "        if name == \"Prophet\":\n",
    "            forecast = model.predict(test_df)[\"yhat\"]\n",
    "        elif name == \"Dynamic Factor\":\n",
    "            forecast = model.predict(start=len(train), end=len(train) + len(test) - 1)\n",
    "        else:\n",
    "            forecast = model.forecast(steps=len(test))\n",
    "\n",
    "        results[name] = {\n",
    "            \"Forecast\": forecast.values,\n",
    "            \"MAE\": round(mean_absolute_error(test[\"Value\"], forecast), 3),\n",
    "            \"RMSE\": round(np.sqrt(mean_squared_error(test[\"Value\"], forecast)),3),\n",
    "            \"MAPE\": round(mean_absolute_percentage_error(test[\"Value\"], forecast), 3),\n",
    "            \"R2\": round(r2_score(test[\"Value\"], forecast),3)\n",
    "            \n",
    "        }\n",
    "\n",
    "    # OpenAI Forecasting\n",
    "\n",
    "    openai_forecast, forecast_summary = forecast_with_openai(train, forecast_periods)\n",
    "    forecast_values = np.array([entry.value for entry in openai_forecast])\n",
    "\n",
    "    \n",
    "\n",
    "    results[\"OpenAI\"] = {\n",
    "        \"Forecast\": openai_forecast,\n",
    "        \"MAE\": round(mean_absolute_error(test[\"Value\"], forecast_values), 3),\n",
    "        \"RMSE\": round(np.sqrt(mean_squared_error(test[\"Value\"], forecast_values)), 3),\n",
    "        \"MAPE\": round(mean_absolute_percentage_error(test[\"Value\"], forecast_values), 3),\n",
    "        \"R2\": round(r2_score(test[\"Value\"], forecast_values),3),\n",
    "        \"Summary\": forecast_summary\n",
    "    }\n",
    "\n",
    "    return train, test, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "# Visualization\n",
    "def plot_results(train, test, results):\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.plot(train[\"Month\"], train[\"Value\"], label=\"Train Data\", color=\"blue\")\n",
    "    plt.plot(test[\"Month\"], test[\"Value\"], label=\"Test Data\", color=\"black\", linestyle=\"dashed\")\n",
    "\n",
    "    for name, res in results.items():\n",
    "        if name == \"OpenAI\":\n",
    "            # Extract values from ForecastEntry objects\n",
    "            forecast_values = np.array([entry.value for entry in res[\"Forecast\"]], dtype=float)\n",
    "        else:\n",
    "            forecast_values = np.array(res[\"Forecast\"], dtype=float)\n",
    "        plt.plot(test[\"Month\"], forecast_values, label=name)\n",
    "\n",
    "\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Month\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.title(\"Forecasting Comparison (Including OpenAI)\")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    metrics_df = pd.DataFrame({name: [res[\"MAE\"], res[\"RMSE\"], res[\"MAPE\"],res[\"R2\"]] for name, res in results.items()},\n",
    "                              index=[\"MAE\", \"RMSE\",\"MAPE\",\"R2\"]).T\n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "test_size=12 should be either positive and smaller than the number of samples 0 or a float in the (0, 1) range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasets/SF229792CFL.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m df \u001b[38;5;241m=\u001b[39m load_and_transform(file_path)\n\u001b[0;32m----> 4\u001b[0m train, test, results \u001b[38;5;241m=\u001b[39m \u001b[43mforecast_time_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRevenue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m==== Result ====\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(results)\n",
      "Cell \u001b[0;32mIn[15], line 4\u001b[0m, in \u001b[0;36mforecast_time_series\u001b[0;34m(df, target_item, forecast_periods)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforecast_time_series\u001b[39m(df, target_item, forecast_periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m):\n\u001b[1;32m      3\u001b[0m     data \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mItem\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m target_item][[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMonth\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValue\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMonth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforecast_periods\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     models \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mARIMA\u001b[39m\u001b[38;5;124m\"\u001b[39m: ARIMA(train[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValue\u001b[39m\u001b[38;5;124m\"\u001b[39m], order\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mfit(),\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHolt-Winters\u001b[39m\u001b[38;5;124m\"\u001b[39m: ExponentialSmoothing(train[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValue\u001b[39m\u001b[38;5;124m\"\u001b[39m], trend\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madd\u001b[39m\u001b[38;5;124m\"\u001b[39m, seasonal\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madd\u001b[39m\u001b[38;5;124m\"\u001b[39m, seasonal_periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m)\u001b[38;5;241m.\u001b[39mfit(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;66;03m# \"Dynamic Factor\": DynamicFactor(train[\"Value\"], k_factors=1).fit()\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     }\n\u001b[1;32m     15\u001b[0m     results \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/Documents/Planful/Hackathon/forecasting_hackathon/venv/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Planful/Hackathon/forecasting_hackathon/venv/lib/python3.9/site-packages/sklearn/model_selection/_split.py:2851\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2848\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[1;32m   2850\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m-> 2851\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2852\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[1;32m   2853\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m   2856\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/Planful/Hackathon/forecasting_hackathon/venv/lib/python3.9/site-packages/sklearn/model_selection/_split.py:2426\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2418\u001b[0m train_size_type \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(train_size)\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind\n\u001b[1;32m   2420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2421\u001b[0m     test_size_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2422\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (test_size \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m n_samples \u001b[38;5;129;01mor\u001b[39;00m test_size \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   2423\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m test_size_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2424\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (test_size \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m test_size \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   2425\u001b[0m ):\n\u001b[0;32m-> 2426\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2427\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_size=\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m should be either positive and smaller\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2428\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m than the number of samples \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m or a float in the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2429\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(0, 1) range\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(test_size, n_samples)\n\u001b[1;32m   2430\u001b[0m     )\n\u001b[1;32m   2432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2433\u001b[0m     train_size_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2434\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (train_size \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m n_samples \u001b[38;5;129;01mor\u001b[39;00m train_size \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   2435\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m train_size_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2436\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (train_size \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m train_size \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   2437\u001b[0m ):\n\u001b[1;32m   2438\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2439\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_size=\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m should be either positive and smaller\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2440\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m than the number of samples \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m or a float in the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2441\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(0, 1) range\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(train_size, n_samples)\n\u001b[1;32m   2442\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: test_size=12 should be either positive and smaller than the number of samples 0 or a float in the (0, 1) range"
     ]
    }
   ],
   "source": [
    "# Usage Example\n",
    "file_path = \"Datasets/SF229792CFL.xlsx\"\n",
    "df = load_and_transform(file_path)\n",
    "train, test, results = forecast_time_series(df, \"Revenue\")\n",
    "print(\"\\n==== Result ====\")\n",
    "print(results)\n",
    "metrics_df = plot_results(train, test, results)\n",
    "\n",
    "display(metrics_df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n=== OpenAI Forecast Summary ===\")\n",
    "print(results[\"OpenAI\"][\"Summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
